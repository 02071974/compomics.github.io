---
name: About
project: pladipus
layout: default
permalink: /pladipus/wiki/about.html
github_project: https://github.com/compomics/pladipus
---

<a href="https://www.youtube.com/watch?v=d3bXgogYYhI" target="_blank"><img src="http://img.youtube.com/vi/d3bXgogYYhI/0.jpg" 
alt="Pladipus video tutorial" width="240" height="180" border="10" /></a>

[Click here for the video](https://www.youtube.com/watch?v=d3bXgogYYhI)

## About

Recent efforts to reveal the “Human Proteome” have caused the field of proteomics to gain momentum. Thanks to the contributing research groups (laboratories of Pandey and Kuster), the results of these studies have brought novel insights into transcriptional and translational mechanisms. Despite the data being publicly available, the unprecedented volume and complexity of proteomics data hampers its (re)usage. Specialized infrastructure in the form of a grid or cluster based computation system is required to process large datasets. These solutions are however known to be expensive and require a lot of expert intervening, putting further restraints on the reusability of proteomics data. This phenomenom is not confined to proteomics and occurs in all other data-intensive fields.

The Platform for Distributed Proteomics Software (**Pladipus**) was developed in response to these challenges. Pladipus is a cheap and accessible grid based computing framework that enables the entire proteomics community to perform large scale reprocessing of public proteomics datasets. It is able to incorporate existing, idle hardware into the processing network, dramatically reducing both the cost and maintenance required. 

The decrease of the total processing time is depending on the size of the machine pool. The more machines that are able to pay their dues, the faster the entire analysis proceeds. Even though the total workload is still enormous, individual machines see no difference between a single search and a behemoth large scale analyses. They are blind to the "bigger picture". As shown in the following graph, when repeating 10 identical searches on various network sizes (each datapoint is the time required by a pladipus network of n size), the total processing time is consistently reduced to waiting for a single analyses, with some overhead related to the networking traffic!

<img src="https://github.com/compomics/pladipus/wiki/Pladipus_Wall_Time.png">
